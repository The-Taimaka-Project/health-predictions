{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rG-dqLJfyAb"
      },
      "outputs": [],
      "source": [
        "# %load_ext jupyter_black"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UX1gf3w1fyAd"
      },
      "outputs": [],
      "source": [
        "# !git clone -b brian-etl-code https://github.com/The-Taimaka-Project/health-predictions.git\n",
        "# !git clone https://github.com/The-Taimaka-Project/health-predictions.git\n",
        "\n",
        "# import sys\n",
        "# sys.path.append('/content/health-predictions')\n",
        "\n",
        "# !pip install boto3\n",
        "# !pip install autogluon.tabular\n",
        "# !pip install shap\n",
        "\n",
        "# import os\n",
        "# from google.colab import userdata\n",
        "# os.environ[\"TAIMAKA_DO_ACCESS_KEY\"] = userdata.get('TAIMAKA_DO_ACCESS_KEY')\n",
        "# os.environ[\"TAIMAKA_DO_SECRET_KEY\"] = userdata.get('TAIMAKA_DO_SECRET_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oyh8tgF5fyAe"
      },
      "outputs": [],
      "source": [
        "# local environment, set up virtual environment\n",
        "# python -m venv .venv\n",
        "# . .venv/bin/activate\n",
        "# then\n",
        "# pip install -r requirements.txt\n",
        "#\n",
        "# or\n",
        "#\n",
        "# pip install jupyter\n",
        "# pip install autogluon.tabular\n",
        "# pip install lightgbm\n",
        "# pip install xgboost\n",
        "# pip install shap\n",
        "\n",
        "\n",
        "%cd ../.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHXjOB_drqs6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from warnings import simplefilter\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from autogluon.features.generators import AutoMLPipelineFeatureGenerator\n",
        "from autogluon.tabular import TabularDataset, TabularPredictor\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from taimaka_health_predictions.inference.util import (\n",
        "    DetnReaderWriter,\n",
        "    ag_feature_generator,\n",
        "    drop_feature_columns,\n",
        "    gbm_shap,\n",
        "    lightgbm_train,\n",
        "    select_features,\n",
        "    split_detn_new_onset_medical_complication,\n",
        "    strip_column_names,\n",
        ")\n",
        "from taimaka_health_predictions.utils.digitalocean import DigitalOceanStorage\n",
        "from taimaka_health_predictions.utils.globals import ETL_DIR, MODEL_DIR, logger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxVY_gL4ooJ3"
      },
      "outputs": [],
      "source": [
        "# run secrets first to set the environment variables for your credentials\n",
        "do_storage = DigitalOceanStorage()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OS7dmhE9Kl9"
      },
      "source": [
        "# get the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0d6M-ZeSppDz"
      },
      "outputs": [],
      "source": [
        "detn_reader = DetnReaderWriter()\n",
        "detn, label = detn_reader.read_detn_weight_loss_ever()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "px-KgdTt5elV"
      },
      "source": [
        "drop the rows that are ineligible for 2 weeks consecutive no weight gain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3k5n38v45okU"
      },
      "outputs": [],
      "source": [
        "detn['wk1_calc_los'].fillna(0,inplace=True)\n",
        "\n",
        "LOS_CUTOFF = 12\n",
        "MUAC_CUTOFF = 12.7\n",
        "logger.info(f'event sum: {detn[label].sum()}, mean: {detn[label].mean()},shape: {detn.shape}')\n",
        "detn = detn[((detn['wk1_b_discharged']==0) & (detn['weekly_last_muac']< MUAC_CUTOFF) & (detn['wk1_calc_los']< LOS_CUTOFF)) ].copy()\n",
        "logger.info(f'event sum: {detn[label].sum()}, mean: {detn[label].mean()},shape: {detn.shape}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "waSllr3CU-wf"
      },
      "outputs": [],
      "source": [
        "detn.drop(columns=['household_adults','household_slept','living_children'],inplace=True)\n",
        "\n",
        "columns_to_keep = {\n",
        "    \"b_referred_emergency\",\n",
        "    \"b_wast_admit\",\n",
        "    \"cg_age\",\n",
        "    \"enr_age\",\n",
        "    \"wk1_age\",\n",
        "    \"wk1_b_wast\",\n",
        "}\n",
        "\n",
        "detn_filtered = drop_feature_columns(\n",
        "    detn,\n",
        "    label,\n",
        "    drop_muac=False,\n",
        "    drop_weight=False,\n",
        "    drop_height=False,\n",
        "    columns_to_keep=columns_to_keep,\n",
        ")\n",
        "logger.info(detn.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40qbJvWg9VSX"
      },
      "source": [
        "# LightGBM iteration for feature selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFP4SyqU5pok"
      },
      "outputs": [],
      "source": [
        "X = detn.drop(columns=label)\n",
        "y = detn[label]\n",
        "\n",
        "# Perform train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=43) # Adjust test_size and random_state as needed\n",
        "\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sz-5Kucw6Ifr"
      },
      "outputs": [],
      "source": [
        "X_train_transformed, X_test_transformed = ag_feature_generator(X_train, X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p56LhtV36m3U"
      },
      "outputs": [],
      "source": [
        "gbm, f1_scored, aic, top_features = lightgbm_train(\n",
        "    X_train_transformed, X_test_transformed, y_train, y_test\n",
        ")\n",
        "print(len(gbm.feature_name_), f1_scored)\n",
        "\n",
        "X_train_transformed_top = X_train_transformed[top_features].copy()\n",
        "X_test_transformed_top = X_test_transformed[top_features].copy()\n",
        "gbm, f1_scored, aic, top_features = lightgbm_train(\n",
        "    X_train_transformed_top, X_test_transformed_top, y_train, y_test\n",
        ")\n",
        "print(len(gbm.feature_name_), f1_scored)\n",
        "\n",
        "best_gbm, best_features, results_df, best_aic, features = select_features(\n",
        "    gbm, X_train_transformed_top, X_test_transformed_top, y_train, y_test, 30, 0, -1\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4kg_sqn6_nz"
      },
      "outputs": [],
      "source": [
        "print(best_aic, \"\\n\", best_features, len(best_features))\n",
        "results_df.sort_values(by=\"AIC\", ascending=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2b2YLJ977osX"
      },
      "outputs": [],
      "source": [
        "N_FEATURES = 9\n",
        "print(N_FEATURES, features[N_FEATURES])\n",
        "\n",
        "top_features = [\n",
        "    col for col in strip_column_names(features[N_FEATURES]) if col in detn.columns\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IX8XnRIcfyAk"
      },
      "outputs": [],
      "source": [
        "gbm_shap(features,N_FEATURES,X_train_transformed,X_test_transformed,X_test_transformed_top,y_train,y_test,cutoff=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZ1sNaiE8X4N"
      },
      "outputs": [],
      "source": [
        "# top_features = ['wk1_weight_diff_rate', 'wk1_calc_los', 'hl_trend', 'hfa_trend', 'wfa_trend', 'weekly_last_muac', 'household_adults_slept_living_children_z', 'weekly_last_wfh']\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W--uI-CF8rPs"
      },
      "source": [
        "# AutoGluon Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8sOTLJ68dl8"
      },
      "outputs": [],
      "source": [
        "# prompt: train test split admit_raw using label column as y\n",
        "\n",
        "\n",
        "# Separate features (X) and target (y)\n",
        "X = detn[top_features]\n",
        "y = detn[label]\n",
        "\n",
        "# Perform train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=43) # Adjust test_size and random_state as needed\n",
        "\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdJOwrtP82sA"
      },
      "outputs": [],
      "source": [
        "AG_PATH = f\"AutogluonModels/{label}\"\n",
        "train_data = TabularDataset(X_train.join(y_train))\n",
        "predictor = TabularPredictor(label=label, eval_metric=\"f1\", path=AG_PATH).fit(\n",
        "    train_data, time_limit=300, presets=\"medium_quality\"\n",
        ")\n",
        "# predictor = TabularPredictor(label=label,eval_metric='f1',path=AG_PATH).fit(train_data,time_limit=600,presets='good_quality')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTGofoba91K3"
      },
      "source": [
        "## evaluate AG model on holdout (i.e., test) data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qchia-w99Tn"
      },
      "outputs": [],
      "source": [
        "test_data = TabularDataset(X_test.join(y_test))\n",
        "predictor.calibrate_decision_threshold()\n",
        "y_pred = predictor.predict(test_data.drop(columns=[label]))\n",
        "print(predictor.evaluate(test_data, silent=True))\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "print(f1_score(y_test,y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieu2ZGB9AEDk"
      },
      "source": [
        "## feature importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Ia3c3HKlAIyU",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "autogluon_feature_importance = predictor.feature_importance(\n",
        "    test_data, subsample_size=1000, time_limit=400\n",
        ")\n",
        "autogluon_feature_importance[\"cumsum\"] = (\n",
        "    autogluon_feature_importance[\"importance\"].cumsum()\n",
        "    / autogluon_feature_importance[\"importance\"].sum()\n",
        ")\n",
        "autogluon_feature_importance[\"importance_ratio\"] = (\n",
        "    autogluon_feature_importance[\"importance\"]\n",
        "    / autogluon_feature_importance[\"importance\"].sum()\n",
        ")\n",
        "autogluon_feature_importance[[\"cumsum\", \"importance_ratio\"]]\n",
        "\n",
        "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "# Bar plot on the primary y-axis\n",
        "autogluon_feature_importance_filtered = autogluon_feature_importance[\n",
        "    autogluon_feature_importance[\"importance\"] > 0\n",
        "]\n",
        "ax1.barh(\n",
        "    autogluon_feature_importance_filtered.index,\n",
        "    autogluon_feature_importance_filtered[\"importance_ratio\"],\n",
        "    label=\"Importance Ratio\",\n",
        ")\n",
        "ax1.set_xlabel(\"Importance\")\n",
        "ax1.set_ylabel(\"Features\")\n",
        "ax1.set_title(\"Feature Importance with Cumulative Sum\")\n",
        "ax1.legend(loc=\"upper left\")  # specify location for the first legend\n",
        "ax1.grid(True, axis=\"x\")  # gridlines only on the x-axis for the bar plot\n",
        "ax1.invert_yaxis()\n",
        "\n",
        "# Create a secondary y-axis\n",
        "ax2 = ax1.twiny()\n",
        "\n",
        "# Line plot on the secondary y-axis\n",
        "ax2.plot(\n",
        "    autogluon_feature_importance_filtered[\"cumsum\"],\n",
        "    autogluon_feature_importance_filtered.index,\n",
        "    marker=\"o\",\n",
        "    linestyle=\"-\",\n",
        "    color=\"red\",\n",
        "    label=\"Cumulative Sum\",\n",
        ")\n",
        "ax2.set_xlabel(\"Cumulative Sum\")\n",
        "ax2.legend(loc=\"upper right\")  # specify location for the second legend\n",
        "\n",
        "# Improve layout\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7h3pMq09eLL"
      },
      "source": [
        "## export the AG model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wh0cHz38_YBV"
      },
      "outputs": [],
      "source": [
        "VERSION = \"0.1.0\"\n",
        "\n",
        "metadata = {\n",
        "    \"version\": VERSION,\n",
        "    \"inputs\": autogluon_feature_importance.sort_values(\n",
        "        by=\"importance\", ascending=False\n",
        "    ).index.tolist(),\n",
        "    \"outputs\": f\"chance of {label}\",\n",
        "    \"description\": (\n",
        "        f\"Predicts chance of {label} given the latest 3 weeks of patient weekly (raw and processed) data plus their admission data. 2 weeks consecutive no weight gain\"\n",
        "    ),\n",
        "    \"feature_engineering\": (\n",
        "        \"wk1_wfh_diff_weekly is the difference between most recent visit and prior visit weight for height, wfh_rsquared is how linear wfh_trend is\"\n",
        "    ),\n",
        "    \"contact\": \"Brian Chaplin\",\n",
        "}\n",
        "\n",
        "path = f\"{MODEL_DIR}{label}/{VERSION}/model.tar.gz\"\n",
        "\n",
        "#do_storage.to_autogluon_tarball(predictor, model_metadata=metadata, path=path)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}