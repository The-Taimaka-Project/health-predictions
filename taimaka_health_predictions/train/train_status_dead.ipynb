{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CNOndj0ZoIzB"
   },
   "outputs": [],
   "source": [
    "# %load_ext jupyter_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54wUh8uiRFtj"
   },
   "source": [
    "uncomment and run below cell if running in Google Colab.  Make sure your secrets are configured in colab and permitted to this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v_rLfHaloIzE"
   },
   "outputs": [],
   "source": [
    "#!pip install boto3\n",
    "#!pip install autogluon.tabular\n",
    "#!pip install shap\n",
    "\n",
    "# !git clone https://github.com/The-Taimaka-Project/health-predictions.git\n",
    "\n",
    "#import sys\n",
    "#sys.path.append('/content/health-predictions')\n",
    "\n",
    "\n",
    "#import os\n",
    "#from google.colab import userdata\n",
    "#os.environ[\"TAIMAKA_DO_ACCESS_KEY\"] = userdata.get('TAIMAKA_DO_ACCESS_KEY')\n",
    "#os.environ[\"TAIMAKA_DO_SECRET_KEY\"] = userdata.get('TAIMAKA_DO_SECRET_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6e4_1XunoIzF"
   },
   "outputs": [],
   "source": [
    "# local environment, set up virtual environment\n",
    "# python -m venv .venv\n",
    "# . .venv/bin/activate\n",
    "# then\n",
    "# pip install -r requirements.txt\n",
    "#\n",
    "# or\n",
    "#\n",
    "# pip install jupyter\n",
    "# pip install autogluon.tabular\n",
    "# pip install lightgbm\n",
    "# pip install xgboost\n",
    "# pip install shap\n",
    "\n",
    "# does nothing in Google Colab but necessary if running locally\n",
    "%cd ../.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fho7zTIPR1kS"
   },
   "source": [
    "if running locally, make sure you run secrets env assignments before running the following cells.  I run the assignments in a separate py file and connect to the kernel running this notebook.\n",
    "\n",
    "\n",
    "```\n",
    "%env TAIMAKA_DO_ACCESS_KEY=your access key\n",
    "%env TAIMAKA_DO_SECRET_KEY=your secret key\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wHXjOB_drqs6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from warnings import simplefilter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from autogluon.features.generators import AutoMLPipelineFeatureGenerator\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score, average_precision_score, PrecisionRecallDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from taimaka_health_predictions.inference.util import (\n",
    "    DetnReaderWriter,\n",
    "    ag_feature_generator,\n",
    "    drop_feature_columns,\n",
    "    gbm_shap,\n",
    "    lightgbm_train,\n",
    "    select_features,\n",
    "    split_detn_new_onset_medical_complication,\n",
    "    strip_column_names,\n",
    ")\n",
    "from taimaka_health_predictions.utils.digitalocean import DigitalOceanStorage\n",
    "from taimaka_health_predictions.utils.globals import ETL_DIR, MODEL_DIR, ADMIT_ONLY, NOT_ADMIT_ONLY, logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NxVY_gL4ooJ3"
   },
   "outputs": [],
   "source": [
    "# run secrets first to set the environment variables for your credentials\n",
    "do_storage = DigitalOceanStorage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2OS7dmhE9Kl9"
   },
   "source": [
    "# get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0d6M-ZeSppDz"
   },
   "outputs": [],
   "source": [
    "detn_reader = DetnReaderWriter()\n",
    "detn, label = detn_reader.read_status_dead()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z5OAmBaRu6qR"
   },
   "outputs": [],
   "source": [
    "LOS_CUTOFF = 11\n",
    "MUAC_CUTOFF = 12.1\n",
    "NULL_MUAC_LOS_CUTOFF = 4\n",
    "DURATION_DAYS_CUTOFF = 101\n",
    "\n",
    "logger.info(f'rate{detn[label].mean()},count {detn[label].sum()},shape{detn.shape}')\n",
    "\n",
    "detn = detn[(((detn['weekly_last_muac'].isnull()) & (detn['wk1_calc_los'] < NULL_MUAC_LOS_CUTOFF)) & (detn['duration_days'] < DURATION_DAYS_CUTOFF) | ((detn['weekly_last_muac'] < MUAC_CUTOFF) & (detn['wk1_calc_los'] < LOS_CUTOFF)))]\n",
    "\n",
    "logger.info(f'rate{detn[label].mean()},count {detn[label].sum()},shape{detn.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n0TX4eSkNzhm"
   },
   "outputs": [],
   "source": [
    "def drop_columns(detn_filtered):\n",
    "  print(detn_filtered.shape)\n",
    "  columns_to_explicitly_delete = {'muac_diff_ratio','muac','household_adults','household_,slept','living_children','resp_rate', 'temperature','weekly_avg_muac','weekly_last_wfh'\n",
    "    'wfa_trend','hfa_trend','cat1_complications_weekly','admit_cat1_complications','wk1_rainy_season_weekly','lean_season_admit','wfh_rsquared','wfh_trend','status','status_date', 'final_date',\n",
    "    'wk1_calcdate_weekly','wk2_calcdate_weekly','wk3_calcdate_weekly'}\n",
    "  columns_to_keep = {\n",
    "    \"b_referred_emergency\",\n",
    "    \"b_wast_admit\",\n",
    "    \"cg_age\",\n",
    "    \"enr_age\",\n",
    "    \"wk1_age\",\n",
    "    \"wk1_b_wast\",\n",
    "  }\n",
    "\n",
    "  detn_filtered = drop_feature_columns(\n",
    "    detn_filtered,\n",
    "    label,\n",
    "    drop_muac=False,\n",
    "    drop_weight=False,\n",
    "    drop_height=False,\n",
    "    columns_to_keep=columns_to_keep,\n",
    "    columns_to_explicitly_delete=columns_to_explicitly_delete\n",
    "  )\n",
    "  print(detn_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aFNEwdWjuA66"
   },
   "outputs": [],
   "source": [
    "detn_admit_only, _, _, _ = split_detn_new_onset_medical_complication(detn, label)\n",
    "pid_not_in_admit = detn[~detn[\"pid\"].isin(detn_admit_only[\"pid\"])][\"pid\"]\n",
    "\n",
    "# Get rows from detn where 'pid' is in pid_not_in_admit\n",
    "detn_filtered = detn[detn[\"pid\"].isin(pid_not_in_admit)].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6tyMCiCjO1-b"
   },
   "outputs": [],
   "source": [
    "drop_columns(detn_filtered)\n",
    "drop_columns(detn_admit_only)\n",
    "detn_admit_only.drop(columns=[col for col in detn_admit_only.columns if 'rsquared' in col],inplace=True)\n",
    "detn_admit_only.drop(columns=[col for col in detn_admit_only.columns if 'trend' in col],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dBMMQe3UO_N4"
   },
   "source": [
    "this notebook trains both strata of the death model\n",
    "\n",
    "\n",
    "1.   death occurs on the first visit, detn_admit_only\n",
    "2.   event occurs on the second or beyond visit, detn_filtered\n",
    "\n",
    "depending on the MODE_ADMIT_ONLY switch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set \n",
    "```\n",
    "MODE_ADMIT_ONLY = True\n",
    "```\n",
    "if you want to train just the events that happened on visit 1, else set to False for events that happened on visit 2 and after\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE_ADMIT_ONLY = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODE_ADMIT_ONLY:\n",
    "  model_suffix = ADMIT_ONLY\n",
    "else:\n",
    "  model_suffix = NOT_ADMIT_ONLY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "40qbJvWg9VSX"
   },
   "source": [
    "# LightGBM iteration for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KFP4SyqU5pok"
   },
   "outputs": [],
   "source": [
    "# prompt: train test split admit_raw using label column as y\n",
    "# Separate features (X) and target (y)\n",
    "\n",
    "if MODE_ADMIT_ONLY:\n",
    "    X = detn_admit_only.drop(columns=label)\n",
    "    y = detn_admit_only[label]\n",
    "else:\n",
    "    X = detn_filtered.drop(columns=label)\n",
    "    y = detn_filtered[label]\n",
    "\n",
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")  # Adjust test_size and random_state as needed\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sz-5Kucw6Ifr"
   },
   "outputs": [],
   "source": [
    "X_train_transformed, X_test_transformed = ag_feature_generator(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p56LhtV36m3U"
   },
   "outputs": [],
   "source": [
    "gbm, f1_scored, aic, top_features,average_precision = lightgbm_train(\n",
    "    X_train_transformed, X_test_transformed, y_train, y_test\n",
    ")\n",
    "print(len(gbm.feature_name_), f1_scored,average_precision)\n",
    "\n",
    "X_train_transformed_top = X_train_transformed[top_features].copy()\n",
    "X_test_transformed_top = X_test_transformed[top_features].copy()\n",
    "gbm, f1_scored, aic, top_features,average_precision = lightgbm_train(\n",
    "    X_train_transformed_top, X_test_transformed_top, y_train, y_test\n",
    ")\n",
    "print(len(gbm.feature_name_), f1_scored,average_precision)\n",
    "\n",
    "best_gbm, best_features, results_df, best_aic, features = select_features(\n",
    "    gbm, X_train_transformed_top, X_test_transformed_top, y_train, y_test, 30, 0, -1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F4kg_sqn6_nz"
   },
   "outputs": [],
   "source": [
    "print(best_aic, \"\\n\", best_features, len(best_features))\n",
    "#results_df.sort_values(by=\"AIC\", ascending=True)\n",
    "results_df.sort_values(by=\"avg_precision\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lmX_uYNpURhQ"
   },
   "source": [
    "the most important part!  Set N_FEATURES to the number of features you want.  Maximize the average precision score but minimize the number of features.  \n",
    "\n",
    "If you want to see what the 10 features selection would be you can run this cell:\n",
    "```\n",
    "print(features[10])\n",
    "```\n",
    "if you want to compare what was removed from the 10th set to get the 9th, you can run a cell like:\n",
    "```\n",
    "print(set(features[10]) - set(features[9]))\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2b2YLJ977osX"
   },
   "outputs": [],
   "source": [
    "N_FEATURES = 3\n",
    "print(N_FEATURES, features[N_FEATURES])\n",
    "\n",
    "top_features = [\n",
    "    col for col in strip_column_names(features[N_FEATURES]) if col in detn.columns\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zCBuukFxV48z"
   },
   "source": [
    "try and get the columns to be independent of one another.  There should be few, if any, clustering bars on the right side of the second graph.  \n",
    "\n",
    "One technique to remove the bars is to combine the clustered features via the reduce_dimensionality method.  Make sure to modify the DetnReaderWriter read_new_onset_medical_complication() method to do this.  Then drop the dimensioned columns in the drop_columns method in this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rCS5q8LDoIzK"
   },
   "outputs": [],
   "source": [
    "gbm_shap(features,N_FEATURES,X_train_transformed,X_test_transformed,X_test_transformed_top,y_train,y_test,cutoff=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W--uI-CF8rPs"
   },
   "source": [
    "# AutoGluon Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_8sOTLJ68dl8"
   },
   "outputs": [],
   "source": [
    "# prompt: train test split admit_raw using label column as y\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "\n",
    "if MODE_ADMIT_ONLY:\n",
    "    X = detn_admit_only[top_features]\n",
    "    y = detn_admit_only[label]\n",
    "else:    \n",
    "    X = detn_filtered[top_features]\n",
    "    y = detn_filtered[label]\n",
    "\n",
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=43\n",
    ")  # Adjust test_size and random_state as needed\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MdJOwrtP82sA"
   },
   "outputs": [],
   "source": [
    "AG_PATH = f\"AutogluonModels/{label}\"\n",
    "train_data = TabularDataset(X_train.join(y_train))\n",
    "# sometimes a good quality model generalizes better than a medium quality one does, depends on the data\n",
    "MEDIUM_QUALITY_MODE = True\n",
    "\n",
    "if MEDIUM_QUALITY_MODE == True:\n",
    "    preset = 'medium_quality'\n",
    "    time_lim = 300\n",
    "else:\n",
    "    preset = 'good_quality'\n",
    "    time_lim = 600\n",
    "\n",
    "predictor = TabularPredictor(label=label, eval_metric=\"average_precision\", path=AG_PATH).fit(\n",
    "    train_data, time_limit=time_lim, presets=preset\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gTGofoba91K3"
   },
   "source": [
    "## evaluate AG model on holdout (i.e., test) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7qchia-w99Tn"
   },
   "outputs": [],
   "source": [
    "test_data2 = TabularDataset(X_test.join(y_test))\n",
    "predictor.calibrate_decision_threshold()\n",
    "y_pred = predictor.predict(test_data2.drop(columns=[label]))\n",
    "print(predictor.evaluate(test_data2, silent=True))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "f1_scored = f1_score(y_test, y_pred)\n",
    "y_pred_proba = predictor.predict_proba(test_data2.drop(columns=[label]))[1]\n",
    "avg_precision = average_precision_score(y_test, y_pred_proba)\n",
    "print('f1: ',f1_scored, 'average precision: ', avg_precision)\n",
    "\n",
    "# Plot the Precision-Recall curve\n",
    "display = PrecisionRecallDisplay.from_predictions(y_test, y_pred_proba, plot_chance_level=True)\n",
    "_ = display.ax_.set_title(f\"Precision-Recall Curve for {label} {model_suffix} \")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ieu2ZGB9AEDk"
   },
   "source": [
    "## feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ia3c3HKlAIyU"
   },
   "outputs": [],
   "source": [
    "autogluon_feature_importance = predictor.feature_importance(\n",
    "    test_data2, subsample_size=1000, time_limit=400\n",
    ")\n",
    "autogluon_feature_importance[\"cumsum\"] = (\n",
    "    autogluon_feature_importance[\"importance\"].cumsum()\n",
    "    / autogluon_feature_importance[\"importance\"].sum()\n",
    ")\n",
    "autogluon_feature_importance[\"importance_ratio\"] = (\n",
    "    autogluon_feature_importance[\"importance\"]\n",
    "    / autogluon_feature_importance[\"importance\"].sum()\n",
    ")\n",
    "autogluon_feature_importance[[\"cumsum\", \"importance_ratio\"]]\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Bar plot on the primary y-axis\n",
    "autogluon_feature_importance_filtered = autogluon_feature_importance[\n",
    "    autogluon_feature_importance[\"importance\"] > 0\n",
    "]\n",
    "ax1.barh(\n",
    "    autogluon_feature_importance_filtered.index,\n",
    "    autogluon_feature_importance_filtered[\"importance_ratio\"],\n",
    "    label=\"Importance Ratio\",\n",
    ")\n",
    "ax1.set_xlabel(\"Importance\")\n",
    "ax1.set_ylabel(\"Features\")\n",
    "ax1.set_title(\"Feature Importance with Cumulative Sum\")\n",
    "ax1.legend(loc=\"upper left\")  # specify location for the first legend\n",
    "ax1.grid(True, axis=\"x\")  # gridlines only on the x-axis for the bar plot\n",
    "ax1.invert_yaxis()\n",
    "\n",
    "# Create a secondary y-axis\n",
    "ax2 = ax1.twiny()\n",
    "\n",
    "# Line plot on the secondary y-axis\n",
    "ax2.plot(\n",
    "    autogluon_feature_importance_filtered[\"cumsum\"],\n",
    "    autogluon_feature_importance_filtered.index,\n",
    "    marker=\"o\",\n",
    "    linestyle=\"-\",\n",
    "    color=\"red\",\n",
    "    label=\"Cumulative Sum\",\n",
    ")\n",
    "ax2.set_xlabel(\"Cumulative Sum\")\n",
    "ax2.legend(loc=\"upper right\")  # specify location for the second legend\n",
    "\n",
    "# Improve layout\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-7h3pMq09eLL"
   },
   "source": [
    "## export the AG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wh0cHz38_YBV"
   },
   "outputs": [],
   "source": [
    "VERSION = \"0.1.0\"\n",
    "\n",
    "metadata = {\n",
    "    \"f1\": f1_scored,\n",
    "    \"average precision\": avg_precision,\n",
    "    \"AG quality\": preset,\n",
    "    \"AG time limit\": time_lim,    \n",
    "    \"version\": VERSION,\n",
    "    \"inputs\": autogluon_feature_importance.sort_values(\n",
    "        by=\"importance\", ascending=False\n",
    "    ).index.tolist(),\n",
    "    \"outputs\": \"chance of death\",\n",
    "    \"description\": (\n",
    "        \"Predicts chance of death\"\n",
    "    ),\n",
    "    \"feature_engineering\": (\n",
    "        \"duration_days is days in program, wfhz_admit is wfh z-score at admittance, household_adults_slept_living_children_z is PCA dimensionalized of normalized ['household_adults', 'household_slept', 'living_children']:  explained variance ratio is [0.64034364]\"\n",
    "#        \"wfh_trend_z is the PCA dimensionalized reduction of normalized ['wfh_rsquared','wfh_trend'] the r-squared and the slope of the linear regression line of the wfh for the patient's history\"\n",
    "    ),\n",
    "    \"contact\": \"Brian Chaplin\",\n",
    "}\n",
    "\n",
    "path = f\"{MODEL_DIR}{label}{model_suffix}/{VERSION}/model.tar.gz\"\n",
    "\n",
    "do_storage.to_autogluon_tarball(predictor, model_metadata=metadata, path=path)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
